{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2 : Supervised learning (1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the algorithms on real case datasets, we are going to experiment them on artificially generated datasets. We call these types of datasets **toy datasets**. Use the appropriate magic command to load the script `datasets.py` (it contains functions to generate toy datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "cmd": "Other",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "markdown": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "cls": "KernelMagics",
        "colors": "BasicMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "copy": "Other",
        "ddir": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "echo": "Other",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "matplotlib": "PylabMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "pip": "BasicMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "profile": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "ren": "Other",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autocall  %automagic  %autosave  %bookmark  %cd  %clear  %cls  %colors  %config  %connect_info  %copy  %ddir  %debug  %dhist  %dirs  %doctest_mode  %echo  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %macro  %magic  %matplotlib  %mkdir  %more  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %popd  %pprint  %precision  %profile  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %ren  %rep  %rerun  %reset  %reset_selective  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%cmd  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load datasets.py # load in the cell\n",
    "%run datasets.py # just run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors : Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are going to use is a set of points which have either the label `0` or `1`. Use the appropriate command to look at the source code of the function `make_forge()` and use it to create a set of points `X` and a set of labels `y`. How many points have been generated ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print source code of make_forge()\n",
    "??make_forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y. How many elements in X ?\n",
    "X, y = make_forge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.96346605,  4.59676542],\n",
       "       [11.0329545 , -0.16816717],\n",
       "       [11.54155807,  5.21116083],\n",
       "       [ 8.69289001,  1.54322016],\n",
       "       [ 8.1062269 ,  4.28695977],\n",
       "       [ 8.30988863,  4.80623966],\n",
       "       [11.93027136,  4.64866327],\n",
       "       [ 9.67284681, -0.20283165],\n",
       "       [ 8.34810316,  5.13415623],\n",
       "       [ 8.67494727,  4.47573059],\n",
       "       [ 9.17748385,  5.09283177],\n",
       "       [10.24028948,  2.45544401],\n",
       "       [ 8.68937095,  1.48709629],\n",
       "       [ 8.92229526, -0.63993225],\n",
       "       [ 9.49123469,  4.33224792],\n",
       "       [ 9.25694192,  5.13284858],\n",
       "       [ 7.99815287,  4.8525051 ],\n",
       "       [ 8.18378052,  1.29564214],\n",
       "       [ 8.7337095 ,  2.49162431],\n",
       "       [ 9.32298256,  5.09840649],\n",
       "       [10.06393839,  0.99078055],\n",
       "       [ 9.50048972, -0.26430318],\n",
       "       [ 8.34468785,  1.63824349],\n",
       "       [ 9.50169345,  1.93824624],\n",
       "       [ 9.15072323,  5.49832246],\n",
       "       [11.563957  ,  1.3389402 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the `matplotlib` library and use the right method to visualize a set of points on a 2D plan. Look at the documentation and use the approriate argument so that points labeled with `0` have a different color from the points with the label `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x956e4a8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEX1JREFUeJzt3X+MZeVdx/HPR5bfEoHuUAsLDjWklhIrcJdgMaRTGrqtBCzqhmojWMym1RpqTBBsdneAGMNqTaM2W9e2EbWBjrUoIBTW7iAlcWFnke3udkGWXy1CutNSqaQJLeXrH+fcMnv33pkzM+fcc5573q9kcn/Mc+9855k7n/uc55znXEeEAADp+Im6CwAALA7BDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABJDcANAYghuAEjMiiqedOXKlTE+Pl7FUwPASNq5c+e3I2KsSNtKgnt8fFwzMzNVPDUAjCTbzxZty1QJACSG4AaAxBDcAJAYghsAEkNwA0BiCO622LRJmp4++L7p6ex+AEkhuNti9Wpp7drXw3t6Oru9enW9dQFYtEqO40YDTUxIU1NZWH/kI9LmzdntiYm6KwOwSIy422RiIgvtm27KLgltIEkEd5tMT2cj7fXrs8veOW8ASSC426I7pz01Jd144+vTJoQ3kByCuy127Dh4Trs7571jR711AVg0R0TpT9rpdIKTTAFAcbZ3RkSnSFtG3ACQGIIbwGho0SIzghvAaGjRIjMW4AAYDS1aZNa+EXeLNqcWhX7BKGjJIrP2BXeLNqf6GhTQTz55aL9ccom0YsWhbQlzNFVbFplFROlf5557bjTatm0RK1dGrF+fXW7bVndFw9P93bu/89zbvf3yiU8Mbgs0zXyv7QRImomCGdvO4I7IwknKLttmvjeu3n5p85sc0nLzzYe+Prdty+5PQOnBLekZSbslPVrkyRsf3IRR/zeuQf3S5jc5YEiqCu6VRZ+00cGd+OZUKfoF9KB+6U6XtPlNDhiCxQR3+w4HnO+cHSO6B/ogc082NTGRfa1dK11++aH9cv310oYN0p13Htx2RA+xAlJR6Fwltp+W9F1JIelvImJLnzbrJK2TpNNOO+3cZ599tuRSUYpNm7IjaOYG7/R09sZ17bVLbwtgWRZzrpKiwX1yRDxv+yRJWyX9fkQ8MKg9J5kCgMUp/SRTEfF8fnlA0u2Szlt6eX2w+AMAClswuG0fa/u47nVJF0vaU2oVbV8UAwCLUGTE/UZJD9reJelhSf8WEV8utYq55xjYsKH8HWCM6AGMkAWDOyKeioi3519vi4g/qaSSKs8xwIgewAhpzrlKqjzHQNUjegAYomYE9zA+yLYlZw0DMPqaEdzD+CDbtpw1DMDIa8eHBfeuFuy9DQBLVdJCNT4suNcwRvRoLo4qQpVqOPihHSNutBtbXKha9zW1jI9MY8QNzMVRRajakA9+ILjRDhxVhCoN+eAHgrsKzKk2D0cVoSrDOJy5B8FdBVZqNksN/1hokRoOfmDnZFVK2FmBknBecSSg9PNxLxbBnduwIZtTXb8+G+kBwAAcVdIEzKkCqAjBXYU2z6myYxaoXHLBPTlZdwUFtHmlJjtmgcolN8dtSxWUjDKxYxZYNOa4US8WuwCVSiK4Jyezkbad3e5eT2LapI3YMQtUiqkSlIsTOgFLwlQJ6tPmHbPAkKyou4DF2rix7gowr34rEScmGG0DJUpuxM28NoC2Sy64AaDtCge37cNs/5ftu6osCAAwv8WMuK+RtK+qQgAAxRQKbturJP2ypM9UWw4AYCFFR9yflHStpNcGNbC9zvaM7ZnZ2dlSigMAHGrB4LZ9iaQDEbFzvnYRsSUiOhHRGRsbK61AAMDBioy4L5B0qe1nJN0m6V22/7HSqgAAAy0Y3BFxfUSsiohxSVdI2hYRH6y8MgBAXxzHDQCJWdSS94i4X9L9lVQCACiEETcAJIbgBoDEENwAkBiCGwASQ3ADQGIIbgBIDMENAIkhuAEgMQQ3ACSG4AaAxBDcAJAYghsAEkNwA0BiCG4ASAzBDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABJDcANAYghuAEgMwQ0AiVkwuG0fZfth27ts77V9wzAKAwD0t6JAm1ckvSsiXrZ9uKQHbd8TEdsrrg0A0MeCwR0RIenl/Obh+VdUWRQAYLBCc9y2D7P9qKQDkrZGxEPVlgUAGKRQcEfEjyLiFyStknSe7bN629heZ3vG9szs7GzZdQIAcos6qiQi/lfS/ZLW9PnelojoRERnbGyspPIAAL2KHFUyZvv4/PrRkt4t6bGqCwMA9FfkqJI3SbrF9mHKgn4qIu6qtiwAwCBFjir5mqSzh1ALAKAAVk4CQGIIbgBIDMENAIkhuAEgMQQ3ACSG4AaAxBDcAJAYghsAEkNw12Bysu4KAKSM4K7BDXyGUPo2bZKmpw++b3o6ux+oGMENLMXq1dLata+H9/R0dnv16nrrQisQ3EMyOSnZ2Zf0+nWmTRI1MSFNTWVhvWFDdjk1ld0PVMzZJ5OVq9PpxMzMTOnPOypsqYJuRx02bJBuuklav1668ca6q0HCbO+MiE6Rtoy4gaWanpY2b85Ce/PmQ+e8gYoQ3DXYuLHuCrBs3TntqalspN2dNiG8MQQEdw2Y1x4BO3YcPKfdnfPesaPeutAKzHEDQAMwxw0AI4zgBoDEENwAkBiCGwASQ3ADQGIIbgBIzILBbftU29O299nea/uaYRQGAOhvRYE2r0r6w4h4xPZxknba3hoRX6+4NgBAHwuOuCPihYh4JL/+f5L2STql6sIAAP0tao7b9riksyU9VEUxGD0s7wfKVzi4bf+kpH+W9LGI+F6f76+zPWN7ZnZ2tswakTA+7QcoX6Hgtn24stD+fER8qV+biNgSEZ2I6IyNjZVZIwBgjiJHlVjSZyXti4i/qL4kpI5P+wGqteDZAW3/kqSvStot6bX87j+OiLsHPYazA6KLT/sBilnM2QEXPBwwIh6U5GVXBQAoBSsnUSk+7QcoH8GNSjGvDZSP4AaAxBDcAJCYVgc3m/EAUtTq4GZVH4AUtTq4ASBFrQvuulb1MS0DoCwLrpxcilRWTg5rVd/kZDYtwwpCAIMsZuVk60bcdWAuHUCZWh3cVa/q607LdHGyJQBlaHVwVxmg3emRXhs3EtwAlqfVc9zD0h11M8cNYBDmuBuIky0BwzeqW7cE9xAwPQLUY1QPDBiZ4G5yMDa5NgDpGZngHtV3VgCL04aPzhuZnZN8RBaAXinlQmt2TrbhnRUAei34mZNNNjn5ekin9M4KYDhG9WiupEfcADCfUd36HpngHtV3VgDoNTLBParvrADQa8Hgtv052wds7xlGQQCA+RUZcf+dpDUV1wE0AltuSMGCwR0RD0h6cQi1ALVjIRdSMDJz3ADQFqUFt+11tmdsz8zOzpb1tEDlWMiF1BRa8m57XNJdEXFWkSflfNxIFQu5UJfWLHkHgDYqcjjgrZL+U9JbbD9n++rqywLqwUIupGDBc5VExAeGUQjQBMxrIwVMlQBAYghuAEgMwQ0AiSG4ASAxBDcAJIbgBoDEENwAkBiCGwASQ3ADQGIIbgBIDMENAIkhuAEgMQQ3ACSG4AaAxBDcAJAYghsAEkNwA0BiCG4ASAzBDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABJTKLhtr7H9uO39tq+ruigAwGALBrftwyR9StJ7JZ0p6QO2z6y6MABAf0VG3OdJ2h8RT0XEDyTdJumyassCAAxSJLhPkfTNObefy+87iO11tmdsz8zOzpZVHwCgR5Hgdp/74pA7IrZERCciOmNjY8uvDADQV5Hgfk7SqXNur5L0fDXlAAAWUiS4d0g6w/bpto+QdIWkO6otC0DTTU7WXUF7LRjcEfGqpI9KulfSPklTEbG36sLQXgRCGm64oe4K2ssRh0xXL1un04mZmZnSnxftYEsVvCxRMv5O5bK9MyI6RdqychKVYvQ8WiYns8B2fshC9zp/5+EiuFGpopvTBEIaJiezUXZ3pN29zt9puJgqQaWWsjnNJnga+DuVi6kS1IrRczts3Fh3Be3FiBuVWsqobHKSkEf7MOJG0ghtYH4ENyrF5jRQPoIblWL0DJSP4AaAxBDcAJAYghsAEkNwA0BiCO6EsKMPgERwJ4XTaAKQCG4ASA7B3XCc9wNAL85VkhDOxgaMLs5VAgAjjOBOCOf9ACAR3ElhXhuARHADQHIIbgBIDMENAIkhuAEgMQQ3ACSmkgU4tmclPbvEh6+U9O0SyylTU2tral0StS1FU+uSqG2pitT2MxExVuTJKgnu5bA9U3T10LA1tbam1iVR21I0tS6J2paq7NqYKgGAxBDcAJCYJgb3lroLmEdTa2tqXRK1LUVT65KobalKra1xc9wAgPk1ccQNAJhHbcFt+w9s77W9x/atto/q+f6Rtr9ge7/th2yPN6Suq2zP2n40//qdYdSV/+xr8rr22v5Yn+/b9l/mffY12+c0qLZ32n5pTr9tqLCWz9k+YHvPnPtOtL3V9hP55QkDHntl3uYJ21c2qK4fzem7O8qsa57afj3/e75me+AREbbX2H48f91d17DanrG9O++30j8kYEBtf2b7sfx/8Hbbxw947NL7LSKG/iXpFElPSzo6vz0l6aqeNr8r6dP59SskfaEhdV0l6a9r6LOzJO2RdIykFZL+XdIZPW3eJ+keSZZ0vqSHGlTbOyXdNaR6LpR0jqQ9c+7bJOm6/Pp1km7u87gTJT2VX56QXz+h7rry771cQ5+9VdJbJN0vqTPgcYdJelLSmyUdIWmXpDObUFve7hlJK4fcbxdLWpFfv3nAa21Z/VbnVMkKSUfbXqHsH/75nu9fJumW/PoXJV1kdz/Aq9a66vJWSdsj4vsR8aqk/5D0/p42l0n6+8hsl3S87Tc1pLahiYgHJL3Yc/fc19Mtkn6lz0PfI2lrRLwYEd+VtFXSmgbUVbl+tUXEvoh4fIGHnidpf0Q8FRE/kHSbst+pCbVVbkBt9+X/B5K0XdKqPg9dVr/VEtwR8T+S/lzSNyS9IOmliLivp9kpkr6Zt39V0kuS3tCAuiTpV/PNoC/aPrXKmubYI+lC22+wfYyy0XXvz/5xn+Wey+9rQm2S9Iu2d9m+x/bbhlDXXG+MiBckKb88qU+bOvqvSF2SdJTtGdvbbdcS7gPU9ZorKiTdZ3un7XU1/PwPKdsK7rWsfqsluPN5vMsknS7pZEnH2v5gb7M+D630EJiCdd0paTwifl7ZlMAtGoKI2Kdss2urpC8r27R6tafZ0PtMKlzbI8qW9L5d0l9J+peq61qCWvqvoNMiW3n3G5I+aftn6y4o1+Q+k6QLIuIcSe+V9Hu2LxzWD7b9cWX/B5/v9+0+9xXut7qmSt4t6emImI2IH0r6kqR39LR5TvmoLZ+2+Ckdupk59Loi4jsR8Up+828lnVtxTXN/9mcj4pyIuFBZXzzR0+THfZZbpSFN9SxUW0R8LyJezq/fLelw2yuHUVvuW91po/zyQJ82dfRfkboUEc/nl08pm9c9u+K6iqrtNVfEnH47IOl2ZVMUlct3bF8i6Tcjn9Tusax+qyu4vyHpfNvH5PPWF0na19PmDkndvfq/JmnbgA4Yal09c8aX9n6/SrZPyi9Pk3S5pFt7mtwh6bfyo0vOVzbV80ITarP90919FLbPU/ba+84wasvNfT1dKelf+7S5V9LFtk/It74uzu+rta68niPz6yslXSDp6xXXVdQOSWfYPt32EcoOJCj9qJelsH2s7eO615X9PffM/6hSfu4aSX8k6dKI+P6AZsvrt6r2thbYG3uDpMeUdeQ/SDpS0o35LytJR0n6J0n7JT0s6c0NqetPJe1VNh0wLennhthnX1X2D7tL0kX5fR+W9OH8uiV9Stne6t2aZ297DbV9dE6/bZf0jgpruVXZPoofKhvZXK1s/8hXlG0JfEXSiXnbjqTPzHnsh/LX3H5Jv92EupRt9e3O+263pKuH1Gfvz6+/Iulbku7N254s6e45j32fpP/OX3cfb0ptyo7Y2JV/7R1ibfuVzV8/mn99ure25fYbKycBIDGsnASAxBDcAJAYghsAEkNwA0BiCG4ASAzBDQCJIbgBIDEENwAk5v8BPtVnH99j5DMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print the points X with matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "X0 = X[y==0,:]\n",
    "X1 = X[y==1,:]\n",
    "plt.plot(X0[:,0], X0[:,1], \"+b\")\n",
    "plt.plot(X1[:,0], X1[:,1], \"xr\")\n",
    "# correction: on peut appeler plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the course, the first step is to separate our dataset into a training and a test part. Use the function `train_test_split()` library to create four variables :\n",
    "* points for training\n",
    "* labels for training\n",
    "* points for test\n",
    "* labels for test\n",
    "\n",
    "Use the parameter `random_state = 0` so the the experiments can be replicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can create a KNN model and specify the parameter `k`. Create a model with `k = 3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create model\n",
    "model = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on your training data (with the `.fit()` method) and evaluate its performance (with the `.score()` method) on the test data. How much accuracy do you get ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We got 85.71% accuracy'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"We got {:.2f}% accuracy\".format(100 * model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to see the boundary decision of our model (ie the line indicating where the points are labeled 0 or 1). Run the following piece of code to see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run plots.py\n",
    "plot_2d_separator(model, X_test, y_test, fill=True, eps=0.5, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create other models with a different value for `k` (use 1, 9 and 15). Train and evaluate each model. Which one is the best one ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model k=1 got 85.71% accuracy\n",
      "Model k=3 got 85.71% accuracy\n",
      "Model k=8 got 85.71% accuracy\n",
      "Model k=15 got 85.71% accuracy\n"
     ]
    }
   ],
   "source": [
    "# models with k = 1, 3, 9, 15\n",
    "for k in [1, 3, 8, 15]:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model k={} got {:.2f}% accuracy\".format(k, 100 * model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the the decision boundary for each of these models. What can be said about the decision boundary when `k` is low ? When `k` is large ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision boundary for each models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn comes with some real case datasets. One of them is the Wisconsin breast cancer dataset. It contains information (measurements) of breast cancer tumors. Each tumor is either \"benign\" or \"malignant\" (so it is a binary classification problem). We are going to use KNN to predict if a tumor is \"benign\" or \"malignant\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "=============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cancer.DESCR) # uncomment for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 569 data points, each one has 30 attributes (called features). The data can be accessed with `cancer.data` and the labels with `cancer.target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(cancer.data.shape)\n",
    "print(cancer.data[0])\n",
    "print(cancer.target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the points into a training and a test datasets with `random_state = 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a KNN classifier with six neighbors and train it with the appropriate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main objective of a classifier model is to be able to predict the label of points we have never seen yet. You can use the `.predict()` method of your classifier and feed it with one or more data points. The result will be the label(s) predicted by your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the accuracy of your model on the entire test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We got 92.31% accuracy'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"We got {:.2f}% accuracy\".format(100 * model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors : Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do regression with the KNN algorithm. Instead of assigning the most frequent label of the k nearest neighbors, we can average the value of the neighbors. Hence we predict a value instead of a class.\n",
    "\n",
    "Use the `make_wave()` function to create a toy dataset of `40` points for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_wave(n_samples=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the points with the following piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.xticks(X, \"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the dataset into a training part and a test part with `random_state = 0`. Then create several models for a KNN regression (at least 3 different models) with different values for the number of neighbors used. Train and evaluate them. What is your best accuracy ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy is 0.77%'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# create train + test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "# create regression models, train and evaluate\n",
    "rmodel = KNeighborsRegressor()\n",
    "rmodel.fit(X_train, y_train)\n",
    "\"accuracy is {:.2f}%\".format(rmodel.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models are mostly used to do regression (predicting a value given a set of features). You can use a linear model to do classification but we will focus on regression in this course. The predicted value $\\hat{y}$ can be written as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{y} = \\sum_{k=1}^n w_k \\times x_k + b\n",
    "\\end{equation*}\n",
    "\n",
    "where $x_k$ are the features of the data points, $w_k$ and $b$ are the parameters learned by the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary Least Squares is the most classic linear method for regression. This model finds the $w$ and $b$ parameters that minimize the **mean squared error (MSE)** between predictions and the true value for the $m$ points in training dataset.\n",
    "\n",
    "\\begin{equation*}\n",
    "MSE = {1 \\over {m}} \\sum_{k=1}^m (\\hat{y}-y)^2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a toy dataset for regression with the function `make_wave()` composed of `80` data points. Then split this dataset into a training and a test dataset with `random_state = 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_wave(n_samples=80)\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create a linear model and train it on the right dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# create model and train it\n",
    "lmodel = LinearRegression()\n",
    "lmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learned $w$ are in the `coef_` attribute while the learned $b$ are in the `intercept_` attribute. Since our data only has one feature, we only have one $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned w: [ 1.95664033e-01 -1.24998359e-02 -1.83925145e-02 -3.08554299e-04\n",
      " -6.58769659e-01  4.67316114e+00 -1.41047944e+00 -1.79519061e+00\n",
      " -1.02466251e+00 -8.16682870e-01 -6.95506836e-01 -2.65194673e-02\n",
      "  6.52894932e-02  3.22253562e-04 -1.16323309e+01 -4.43943865e-02\n",
      "  3.04134165e+00 -8.31729413e+00 -2.44644000e+00  1.96844051e+01\n",
      " -1.78964757e-01 -2.00410588e-04 -4.02896117e-03  1.17548563e-03\n",
      " -4.04988322e-01 -1.15267671e-01 -4.11583121e-01 -9.11239745e-01\n",
      " -1.12925131e-01 -5.02459596e+00]\n",
      "Learned b: 3.2643236829496516\n"
     ]
    }
   ],
   "source": [
    "print(\"Learned w:\", lmodel.coef_)\n",
    "print(\"Learned b:\", lmodel.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way as before, we can compute the estimate output with the `predict()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction = [0.18812197]\n",
      "Hand computed prediction = [  5.88622173   7.27934964  20.60798357 112.19049087   3.28596413\n",
      "   3.29306673   3.29259714   3.28031335   3.30572619   3.27865607\n",
      "   3.34075005   3.44640863   3.86951254   9.85233168   3.26538301\n",
      "   3.26875547   3.27107801   3.26693384   3.26765975   3.26510732\n",
      "   6.47517047   9.0677189   25.43305863 168.48303318   3.2951212\n",
      "   3.33977173   3.36422974   3.30445438   3.33446924   3.28602282]\n",
      "Correct output = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Model prediction =\", lmodel.predict([X_test[0]]))\n",
    "print(\"Hand computed prediction =\", lmodel.coef_[0] * X_test[0] + lmodel.intercept_)\n",
    "print(\"Correct output =\", y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to predict the price of houses given some features. The data come from the housing market in Boston. We have 506 data points, and each one has 104 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 104)\n",
      "(506,)\n",
      "[24.  21.6 34.7]\n"
     ]
    }
   ],
   "source": [
    "X, y = load_extended_boston()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y[:3]) # some house prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape are (379, 104) (127, 104) (379,) (127,)\n",
      "predicted price of first element is 23.673943519339847\n",
      "real price of first element is 22.6\n"
     ]
    }
   ],
   "source": [
    "# separate the data into a training set and a test set with\n",
    "# random_state = 0. Then train a linear model and predict the\n",
    "# price of the first house in the test set. Compare it with the \n",
    "# actual price of the house.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "print(\"data shape are\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "lmodel = LinearRegression()\n",
    "lmodel.fit(X_train, y_train)\n",
    "print(\"predicted price of first element is\", *lmodel.predict([X_test[0]]))\n",
    "print(\"real price of first element is\", y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523526436864238\n",
      "0.6057754892935543\n",
      "Our model is overfitting a lot because the result on the training set are very good compared to the result on the test set.\n"
     ]
    }
   ],
   "source": [
    "# we can also compute the score of the model. Compare\n",
    "# the score obtained on the training data and the score\n",
    "# on the test data. \n",
    "# Do you thing we are underfitting or overfitting ? Explain why ?\n",
    "print(\"score on the training set:\", lmodel.score(X_train, y_train))\n",
    "print(\"score on the test set:\", lmodel.score(X_test, y_test))\n",
    "print(\"Our model is overfitting a lot because the result on the training set are\\\n",
    " very good compared to the result on the test set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the linear model can overfit. This means that it will be good on the training set, but not on the test set. One way to control overfitting is to add a regularization to our model. We can add a constraint to the objective being minimized by the model.\n",
    "\n",
    "We will see a L2 normalization that minimizes the norm 2 of the weights $w$ of the model. The name of this new type of model is called **Ridge regression** and it minimizes :\n",
    "\n",
    "\\begin{equation*}\n",
    "MSE + Regularization = {1 \\over {m}} \\sum_{k=1}^m (\\hat{y}-y)^2 + \\lambda \\left\\lVert w \\right\\rVert ^2\n",
    "\\end{equation*}\n",
    "\n",
    "$\\lambda$ is a parameter to adjust the effect of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8860578560395835\n",
      "0.7527139600306949\n",
      "The results are weaker on the training set, but much better on the test set:we reduced the overfiting a lot (but it is still present)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# create a model Ridge, train it on the same training\n",
    "# set made of the Housing market and evaluate its\n",
    "# training score and test score. Do you have any improvement ?\n",
    "# Is it better compared to a model with no regularization ?\n",
    "\n",
    "rmodel = Ridge()\n",
    "rmodel.fit(X_train, y_train)\n",
    "print(rmodel.score(X_train, y_train))\n",
    "print(rmodel.score(X_test, y_test))\n",
    "print(\"The results are weaker on the training set, but much better on the test set:\\\n",
    "we reduced the overfiting a lot (but it is still present)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building Ridge model with alpha = 0.01\n",
      " | score on the training set: 0.94\n",
      " | score on the test set: 0.70\n",
      "building Ridge model with alpha = 0.02\n",
      " | score on the training set: 0.94\n",
      " | score on the test set: 0.73\n",
      "building Ridge model with alpha = 0.05\n",
      " | score on the training set: 0.93\n",
      " | score on the test set: 0.76\n",
      "building Ridge model with alpha = 0.1\n",
      " | score on the training set: 0.93\n",
      " | score on the test set: 0.77\n",
      "building Ridge model with alpha = 0.2\n",
      " | score on the training set: 0.92\n",
      " | score on the test set: 0.77\n",
      "building Ridge model with alpha = 0.5\n",
      " | score on the training set: 0.90\n",
      " | score on the test set: 0.77\n",
      "building Ridge model with alpha = 1\n",
      " | score on the training set: 0.89\n",
      " | score on the test set: 0.75\n",
      "building Ridge model with alpha = 2\n",
      " | score on the training set: 0.86\n",
      " | score on the test set: 0.73\n",
      "building Ridge model with alpha = 5\n",
      " | score on the training set: 0.82\n",
      " | score on the test set: 0.68\n",
      "building Ridge model with alpha = 10\n",
      " | score on the training set: 0.79\n",
      " | score on the test set: 0.64\n",
      "\n",
      "The alpha parametter seems to influance how close we train the model to the training set:Too litle and we overfit, too much and we overfit.\n"
     ]
    }
   ],
   "source": [
    "# try different Ridge() models with different values for\n",
    "# the alpha parameter (read the documentation if necessary).\n",
    "# Then compute the training and test scores for each model.\n",
    "# Can you tell what is the influence of alpha on the scores ?\n",
    "for a in [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]:\n",
    "    print(\"building Ridge model with alpha =\", a)\n",
    "    rmodel = Ridge(alpha=a)\n",
    "    rmodel.fit(X_train, y_train)\n",
    "    print(\" | score on the training set: {:.2f}\".format(rmodel.score(X_train, y_train)))\n",
    "    print(\" | score on the test set: {:.2f}\".format(rmodel.score(X_test, y_test)))\n",
    "\n",
    "print()\n",
    "print(\"The alpha parametter seems to influance how close we train the model to the training set:\\\n",
    "Too litle and we overfit, too much and we overfit.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
